### SETTINGS ###
anchor_drawing = house
negative_drawings = ['airplane', 'face', 'bathtub', 'cloud', 'mailbox']
number of samples per drawing category = 10
epochs = 150
margin = 120
learning_rate = 0.001
metric = l2-norm
loss_function = ContrastiveLoss
###

before:
pos = 52.31465530395508, 46.507450103759766 	(avg: 49.2095947265625)
neg1 = 70.01513671875, 66.1571044921875 	(avg: 62.98496627807617)
neg2 = 61.81850814819336, 66.1571044921875 	(avg: 61.98998260498047)

Epoch 1, Loss: 3116.490234375
Epoch 2, Loss: 3179.526123046875
Epoch 3, Loss: 2878.655517578125
Epoch 4, Loss: 2810.174072265625
Epoch 5, Loss: 2748.9951171875
Epoch 6, Loss: 2660.6083984375
Epoch 7, Loss: 2577.638427734375
Epoch 8, Loss: 2518.6201171875
Epoch 9, Loss: 2491.719482421875
Epoch 10, Loss: 2464.077392578125
Epoch 11, Loss: 2433.84375
Epoch 12, Loss: 2408.232421875
Epoch 13, Loss: 2388.069091796875
Epoch 14, Loss: 2370.205322265625
Epoch 15, Loss: 2351.854248046875
Epoch 16, Loss: 2332.39013671875
Epoch 17, Loss: 2312.8994140625
Epoch 18, Loss: 2294.945556640625
Epoch 19, Loss: 2279.322021484375
Epoch 20, Loss: 2265.648681640625
Epoch 21, Loss: 2252.997314453125
Epoch 22, Loss: 2240.66259765625
Epoch 23, Loss: 2228.46240234375
Epoch 24, Loss: 2216.52294921875
Epoch 25, Loss: 2204.858154296875
Epoch 26, Loss: 2193.198974609375
Epoch 27, Loss: 2181.249755859375
Epoch 28, Loss: 2168.990478515625
Epoch 29, Loss: 2156.558837890625
Epoch 30, Loss: 2144.03662109375
Epoch 31, Loss: 2131.4931640625
Epoch 32, Loss: 2119.11181640625
Epoch 33, Loss: 2107.1484375
Epoch 34, Loss: 2095.761962890625
Epoch 35, Loss: 2084.9326171875
Epoch 36, Loss: 2074.518798828125
Epoch 37, Loss: 2064.37548828125
Epoch 38, Loss: 2054.42626953125
Epoch 39, Loss: 2044.6427001953125
Epoch 40, Loss: 2035.0380859375
Epoch 41, Loss: 2025.61328125
Epoch 42, Loss: 2016.3514404296875
Epoch 43, Loss: 2007.2310791015625
Epoch 44, Loss: 1998.2447509765625
Epoch 45, Loss: 1989.43603515625
Epoch 46, Loss: 1980.8582763671875
Epoch 47, Loss: 1972.5374755859375
Epoch 48, Loss: 1964.479736328125
Epoch 49, Loss: 1956.6981201171875
Epoch 50, Loss: 1949.2408447265625
Epoch 51, Loss: 1942.1566162109375
Epoch 52, Loss: 1923.7537841796875
Epoch 53, Loss: 1905.3446044921875
Epoch 54, Loss: 1889.26806640625
Epoch 55, Loss: 1871.538330078125
Epoch 56, Loss: 1856.6075439453125
Epoch 57, Loss: 1842.8712158203125
Epoch 58, Loss: 1827.6435546875
Epoch 59, Loss: 1813.57421875
Epoch 60, Loss: 1800.4422607421875
Epoch 61, Loss: 1787.21044921875
Epoch 62, Loss: 1773.6141357421875
Epoch 63, Loss: 1760.1409912109375
Epoch 64, Loss: 1747.081298828125
Epoch 65, Loss: 1734.0775146484375
Epoch 66, Loss: 1720.9061279296875
Epoch 67, Loss: 1707.87109375
Epoch 68, Loss: 1695.2322998046875
Epoch 69, Loss: 1682.810791015625
Epoch 70, Loss: 1670.5804443359375
Epoch 71, Loss: 1658.622802734375
Epoch 72, Loss: 1647.021728515625
Epoch 73, Loss: 1635.679443359375
Epoch 74, Loss: 1624.529541015625
Epoch 75, Loss: 1613.6661376953125
Epoch 76, Loss: 1603.0372314453125
Epoch 77, Loss: 1592.6026611328125
Epoch 78, Loss: 1582.343505859375
Epoch 79, Loss: 1572.26806640625
Epoch 80, Loss: 1562.3970947265625
Epoch 81, Loss: 1552.683837890625
Epoch 82, Loss: 1543.1644287109375
Epoch 83, Loss: 1533.8519287109375
Epoch 84, Loss: 1524.6964111328125
Epoch 85, Loss: 1515.6881103515625
Epoch 86, Loss: 1506.854736328125
Epoch 87, Loss: 1498.1976318359375
Epoch 88, Loss: 1489.678955078125
Epoch 89, Loss: 1481.318115234375
Epoch 90, Loss: 1473.137451171875
Epoch 91, Loss: 1465.114013671875
Epoch 92, Loss: 1457.2412109375
Epoch 93, Loss: 1449.52001953125
Epoch 94, Loss: 1441.9327392578125
Epoch 95, Loss: 1434.4705810546875
Epoch 96, Loss: 1427.1253662109375
Epoch 97, Loss: 1419.8746337890625
Epoch 98, Loss: 1412.69140625
Epoch 99, Loss: 1405.55859375
Epoch 100, Loss: 1398.456298828125
Epoch 101, Loss: 1391.3741455078125
Epoch 102, Loss: 1389.0811767578125
Epoch 103, Loss: 1386.842529296875
Epoch 104, Loss: 1384.6221923828125
Epoch 105, Loss: 1382.4144287109375
Epoch 106, Loss: 1380.2061767578125
Epoch 107, Loss: 1378.0023193359375
Epoch 108, Loss: 1375.7994384765625
Epoch 109, Loss: 1373.5948486328125
Epoch 110, Loss: 1371.3917236328125
Epoch 111, Loss: 1369.1856689453125
Epoch 112, Loss: 1366.97802734375
Epoch 113, Loss: 1364.7696533203125
Epoch 114, Loss: 1362.5565185546875
Epoch 115, Loss: 1360.3402099609375
Epoch 116, Loss: 1358.119873046875
Epoch 117, Loss: 1355.8936767578125
Epoch 118, Loss: 1353.6617431640625
Epoch 119, Loss: 1351.425048828125
Epoch 120, Loss: 1349.1800537109375
Epoch 121, Loss: 1346.9287109375
Epoch 122, Loss: 1344.66943359375
Epoch 123, Loss: 1342.402587890625
Epoch 124, Loss: 1340.1278076171875
Epoch 125, Loss: 1337.843994140625
Epoch 126, Loss: 1335.55224609375
Epoch 127, Loss: 1333.25244140625
Epoch 128, Loss: 1330.943603515625
Epoch 129, Loss: 1328.626708984375
Epoch 130, Loss: 1326.3011474609375
Epoch 131, Loss: 1323.9652099609375
Epoch 132, Loss: 1321.621826171875
Epoch 133, Loss: 1319.2685546875
Epoch 134, Loss: 1316.9068603515625
Epoch 135, Loss: 1314.5355224609375
Epoch 136, Loss: 1312.1544189453125
Epoch 137, Loss: 1309.764404296875
Epoch 138, Loss: 1307.3638916015625
Epoch 139, Loss: 1304.9549560546875
Epoch 140, Loss: 1302.53662109375
Epoch 141, Loss: 1300.1060791015625
Epoch 142, Loss: 1297.66845703125
Epoch 143, Loss: 1295.2205810546875
Epoch 144, Loss: 1292.7628173828125
Epoch 145, Loss: 1290.295654296875
Epoch 146, Loss: 1287.81884765625
Epoch 147, Loss: 1285.336181640625
Epoch 148, Loss: 1282.8419189453125
Epoch 149, Loss: 1280.340087890625
Epoch 150, Loss: 1277.82958984375
	 -> training-time: 50.27 min.

after:
pos = 64.49596405029297, 53.89346694946289 	(avg: 60.30562210083008)
neg1 = 102.88481140136719, 94.41028594970703 	(avg: 94.93067932128906)
neg2 = 92.96004486083984, 94.41028594970703 	(avg: 92.22261047363281)

