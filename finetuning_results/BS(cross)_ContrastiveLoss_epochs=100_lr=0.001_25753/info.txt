### SETTINGS ###
anchors = ['seitenansicht', 'draufsicht', 'deck', 'widerlager']
epochs = 100
margin = 1
learning_rate = 0.001
metric = l2-norm
loss_function = ContrastiveLoss
###

Epoch 1, Loss: 0.2415676712989807
Epoch 2, Loss: 0.2027188390493393
Epoch 3, Loss: 0.20767679810523987
Epoch 4, Loss: 0.21631087362766266
Epoch 5, Loss: 0.21541954576969147
Epoch 6, Loss: 0.21837326884269714
Epoch 7, Loss: 0.21800029277801514
Epoch 8, Loss: 0.21188810467720032
Epoch 9, Loss: 0.20714589953422546
Epoch 10, Loss: 0.20547723770141602
Epoch 11, Loss: 0.20476919412612915
Epoch 12, Loss: 0.2032899409532547
Epoch 13, Loss: 0.2006537765264511
Epoch 14, Loss: 0.19844543933868408
Epoch 15, Loss: 0.19698572158813477
Epoch 16, Loss: 0.1956404745578766
Epoch 17, Loss: 0.19394013285636902
Epoch 18, Loss: 0.19248437881469727
Epoch 19, Loss: 0.19181469082832336
Epoch 20, Loss: 0.19075120985507965
Epoch 21, Loss: 0.18918980658054352
Epoch 22, Loss: 0.18675348162651062
Epoch 23, Loss: 0.18565399944782257
Epoch 24, Loss: 0.18261341750621796
Epoch 25, Loss: 0.18523216247558594
Epoch 26, Loss: 0.1835506558418274
Epoch 27, Loss: 0.1827109307050705
Epoch 28, Loss: 0.1827833354473114
Epoch 29, Loss: 0.1795254796743393
Epoch 30, Loss: 0.18188954889774323
Epoch 31, Loss: 0.1805596947669983
Epoch 32, Loss: 0.17817936837673187
Epoch 33, Loss: 0.17538222670555115
Epoch 34, Loss: 0.1757482886314392
Epoch 35, Loss: 0.17629018425941467
Epoch 36, Loss: 0.17608824372291565
Epoch 37, Loss: 0.173919677734375
Epoch 38, Loss: 0.17353276908397675
Epoch 39, Loss: 0.17271293699741364
Epoch 40, Loss: 0.17017969489097595
Epoch 41, Loss: 0.17215417325496674
Epoch 42, Loss: 0.17253641784191132
Epoch 43, Loss: 0.172174334526062
Epoch 44, Loss: 0.1700800359249115
Epoch 45, Loss: 0.1693314164876938
Epoch 46, Loss: 0.16960632801055908
Epoch 47, Loss: 0.16813595592975616
Epoch 48, Loss: 0.16781018674373627
Epoch 49, Loss: 0.16714005172252655
Epoch 50, Loss: 0.1672353446483612
Epoch 51, Loss: 0.18231156468391418
Epoch 52, Loss: 0.19251370429992676
Epoch 53, Loss: 0.18431882560253143
Epoch 54, Loss: 0.18513113260269165
Epoch 55, Loss: 0.18434883654117584
Epoch 56, Loss: 0.18043990433216095
Epoch 57, Loss: 0.17961174249649048
Epoch 58, Loss: 0.1762910932302475
Epoch 59, Loss: 0.17381949722766876
Epoch 60, Loss: 0.1692388504743576
Epoch 61, Loss: 0.16580849885940552
Epoch 62, Loss: 0.16579468548297882
Epoch 63, Loss: 0.16510649025440216
Epoch 64, Loss: 0.16682294011116028
Epoch 65, Loss: 0.17232830822467804
Epoch 66, Loss: 0.16517667472362518
Epoch 67, Loss: 0.16245797276496887
Epoch 68, Loss: 0.16441580653190613
Epoch 69, Loss: 0.15936090052127838
Epoch 70, Loss: 0.1586672067642212
Epoch 71, Loss: 0.16055473685264587
Epoch 72, Loss: 0.15904757380485535
Epoch 73, Loss: 0.15895330905914307
Epoch 74, Loss: 0.15768764913082123
Epoch 75, Loss: 0.156733438372612
Epoch 76, Loss: 0.15774445235729218
Epoch 77, Loss: 0.15630774199962616
Epoch 78, Loss: 0.15467000007629395
Epoch 79, Loss: 0.15332777798175812
Epoch 80, Loss: 0.15432429313659668
Epoch 81, Loss: 0.1539255827665329
Epoch 82, Loss: 0.15326185524463654
Epoch 83, Loss: 0.15204288065433502
Epoch 84, Loss: 0.15000659227371216
Epoch 85, Loss: 0.1499321460723877
Epoch 86, Loss: 0.14961016178131104
Epoch 87, Loss: 0.14922524988651276
Epoch 88, Loss: 0.1483696699142456
Epoch 89, Loss: 0.14797824621200562
Epoch 90, Loss: 0.14668168127536774
Epoch 91, Loss: 0.14531557261943817
Epoch 92, Loss: 0.14482736587524414
Epoch 93, Loss: 0.14475944638252258
Epoch 94, Loss: 0.13783758878707886
Epoch 95, Loss: 0.13841886818408966
Epoch 96, Loss: 0.13534171879291534
Epoch 97, Loss: 0.13772405683994293
Epoch 98, Loss: 0.1329878717660904
Epoch 99, Loss: 0.11994068324565887
Epoch 100, Loss: 0.11992067098617554
	 -> training-time: 61.17 min.
